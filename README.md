# Analyzing the Quality of Concepts Learned by Self-Explainable and Foundation Models
This code allows to train explainable models (GlanceNet, CBM) and Visual-Language Concept Bottleneck Models on two possible datasets: Shapes3d and CelebA. It also allows to collect the metrics relevant to assess concept quality: disentanglement, completeness, leakage.
## Instructions

## Master Thesis
This is the work for my Master thesis at the University of Trento in 2024.

## References
Part of the code was taken from other sources. I will list them here:

[GlanceNet](https://arxiv.org/abs/2205.15612), [Emanuele Marconato](https://github.com/ema-marconato)

[Language in a Bottle](https://arxiv.org/abs/2211.11158)

[Label-free Concept Bottleneck Models](https://openreview.net/pdf?id=FlCg47MNvBA)

[DCI](https://arxiv.org/abs/2210.00364)




